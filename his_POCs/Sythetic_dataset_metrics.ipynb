{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from his.rcnn_utils import *\n",
    "import his.metrics\n",
    "import his.models as crnn\n",
    "from torchvision.transforms import v2\n",
    "from torch.nn import init\n",
    "from collections import namedtuple\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from discordwebhook import Discord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets:\n",
    "\n",
    "- RP500, RP1000\n",
    "- RT500, RT1000\n",
    "- PP500, PP1000\n",
    "- PT500, PP1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split(loader: Dataset, split: list, seed: torch.Generator) -> Data:\n",
    "    return Data(*random_split(\n",
    "        loader,\n",
    "        split,\n",
    "        seed\n",
    "    )[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset class\n",
    "Dataset = namedtuple(\"Dataset\", [\"name\", \"train\", \"val\", \"test\"])\n",
    "\n",
    "# datasets \n",
    "dRP500 = load_and_split(\n",
    "    BaseRcnnDataset(\"../data/DRect_plain_1000/data/\", \"../data/DRect_plain_1000/RCNNAnnotations/\"),\n",
    "    [400, 50, 50, 500],\n",
    "    torch.Generator().manual_seed(10)\n",
    "    )\n",
    "dRP500 = Dataset(\"dRP500\", dRP500.train, dRP500.val, dRP500.test)\n",
    "\n",
    "dRP1000 = load_and_split(\n",
    "    BaseRcnnDataset(\"../data/DRect_plain_1000/data/\", \"../data/DRect_plain_1000/RCNNAnnotations/\"),\n",
    "    [800, 100, 100],\n",
    "    torch.Generator().manual_seed(10)\n",
    "    )\n",
    "dRP1000 = Dataset(\"dRP1000\", dRP1000.train, dRP1000.val, dRP1000.test)\n",
    "\n",
    "dRT500 = load_and_split(\n",
    "    BaseRcnnDataset(\"../data/DRect_texture_1000/data/\", \"../data/DRect_texture_1000/RCNNAnnotations/\"),\n",
    "    [400, 50, 50, 500],\n",
    "    torch.Generator().manual_seed(10)\n",
    "    )\n",
    "dRT500 = Dataset(\"dRT500\", dRT500.train, dRT500.val, dRT500.test)\n",
    "\n",
    "dRT1000 = load_and_split(\n",
    "    BaseRcnnDataset(\"../data/DRect_texture_1000/data/\", \"../data/DRect_texture_1000/RCNNAnnotations/\"),\n",
    "    [800, 100, 100],\n",
    "    torch.Generator().manual_seed(10)\n",
    "    )\n",
    "dRT1000 = Dataset(\"dRT1000\", dRT1000.train, dRT1000.val, dRT1000.test)\n",
    "\n",
    "dPP500 = load_and_split(\n",
    "    BaseRcnnDataset(\"../data/DPoly_plain_1000/data/\", \"../data/DPoly_plain_1000/RCNNAnnotations/\"),\n",
    "    [400, 50, 50, 500],\n",
    "    torch.Generator().manual_seed(10)\n",
    "    )\n",
    "dPP500 = Dataset(\"dPP500\", dPP500.train, dPP500.val, dPP500.test)\n",
    "\n",
    "dPP1000 = load_and_split(\n",
    "    BaseRcnnDataset(\"../data/DPoly_plain_1000/data/\", \"../data/DPoly_plain_1000/RCNNAnnotations/\"),\n",
    "    [800, 100, 100],\n",
    "    torch.Generator().manual_seed(10)\n",
    "    )\n",
    "dPP1000 = Dataset(\"dPP1000\", dPP1000.train, dPP1000.val, dPP1000.test)\n",
    "\n",
    "dPT500 = load_and_split(\n",
    "    BaseRcnnDataset(\"../data/DPoly_texture_1000/data/\", \"../data/DPoly_texture_1000/RCNNAnnotations/\"),\n",
    "    [400, 50, 50, 500],\n",
    "    torch.Generator().manual_seed(10)\n",
    "    )\n",
    "dPT500 = Dataset(\"dPT500\", dPT500.train, dPT500.val, dPT500.test)\n",
    "\n",
    "dPT1000 = load_and_split(\n",
    "    BaseRcnnDataset(\"../data/DPoly_texture_1000/data/\", \"../data/DPoly_texture_1000/RCNNAnnotations/\"),\n",
    "    [800, 100, 100],\n",
    "    torch.Generator().manual_seed(10)\n",
    "    )\n",
    "dPT1000 = Dataset(\"dPT1000\", dPT1000.train, dPT1000.val, dPT1000.test)\n",
    "\n",
    "DATASETS = [\n",
    "    dRP500, dRP1000,\n",
    "    dRT500, dRT1000,\n",
    "    dPP500, dPP1000,\n",
    "    dPT500, dPT1000\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Base cells:\n",
    "- RNN-cell\n",
    "- LSTM-cell\n",
    "- GRU-cell\n",
    "\n",
    "Variants:\n",
    "- 2 Convolutional Layers\n",
    "- SegNet\n",
    "- UNet\n",
    "\n",
    "$3\\times 3 = 9$ combinations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base cells\n",
    "\n",
    "- 2 Convolutiona layers\n",
    "- SegNet\n",
    "- UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2Layers(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.process = nn.Sequential(\n",
    "          nn.Conv2d(in_channels, in_channels, 5, 1, 2),\n",
    "          nn.BatchNorm2d(in_channels),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "        )\n",
    "        \n",
    "        init.orthogonal_(self.process[0].weight)\n",
    "        init.orthogonal_(self.process[-1].weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.process(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SegNet = lambda x, y: nn.Sequential(\n",
    "    nn.Conv2d(x, 64, 3, 1, 1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    \n",
    "    nn.Conv2d(64, 128, 3, 1, 1),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.05),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    \n",
    "    nn.Conv2d(128, 128, 3, 1, 1),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.05),\n",
    "    \n",
    "    nn.ConvTranspose2d(128, 64, 2, 2),\n",
    "    nn.Conv2d(64, 64, 3, 1, 1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.ConvTranspose2d(64, 32, 2, 2),\n",
    "    nn.Conv2d(32, 32, 3, 1, 1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, y, 3, 1, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False), # no bias for batch norm\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=3, \n",
    "        out_channels=1,\n",
    "        features=[64, 128, 256, 512],\n",
    "        dropout=0.,\n",
    "        DoubleConv = DoubleConv\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # downs\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "            \n",
    "        # ups\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature*2,\n",
    "                    feature,\n",
    "                    2,\n",
    "                    2\n",
    "                )\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "            \n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        \n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "            x = nn.functional.dropout2d(x, self.dropout)\n",
    "            \n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        \n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "            \n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = TF.resize(x, size=skip_connection.shape[2:], antialias=True)\n",
    "            \n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "            x = nn.functional.dropout2d(x, self.dropout)\n",
    "            \n",
    "        return self.final_conv(x)\n",
    "    \n",
    "    def grad_norm(self):\n",
    "        total_norm = 0.0\n",
    "        for param in self.parameters():\n",
    "            if param.grad is not None:\n",
    "                param_norm = param.grad.data.norm(2)\n",
    "                total_norm += param_norm.item() ** 2\n",
    "\n",
    "        return total_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = namedtuple('Model', ['name', 'init'])\n",
    "\n",
    "MODELS = [\n",
    "    Model('RNN-2C', lambda: crnn.ConvRNNCell(3, 200, 200, Conv2Layers)),\n",
    "    Model('RNN-SegNet', lambda: crnn.ConvRNNCell(3, 200, 200, SegNet)),\n",
    "    Model('RNN-UNet', lambda: crnn.ConvRNNCell(3, 200, 200, UNet)),\n",
    "    \n",
    "    Model('LSTM-2C', lambda: crnn.ConvLSTMCell(3, 200, 200, Conv2Layers)),\n",
    "    Model('LSTM-SegNet', lambda: crnn.ConvLSTMCell(3, 200, 200, SegNet)),\n",
    "    Model('LSTM-UNet', lambda: crnn.ConvLSTMCell(3, 200, 200, UNet)),\n",
    "    \n",
    "    Model('GRU-2C', lambda: crnn.ConvGRUCell(3, 200, 200, Conv2Layers)),\n",
    "    Model('GRU-SegNet', lambda: crnn.ConvGRUCell(3, 200, 200, SegNet)),\n",
    "    Model('GRU-UNet', lambda: crnn.ConvGRUCell(3, 200, 200, UNet)),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(prediction, target, threshold=0.5, smooth=1e-5, norm=1):\n",
    "    prediction_binary = (prediction > threshold).float()\n",
    "    \n",
    "    target /= norm\n",
    "    intersection = torch.sum(prediction_binary * target)\n",
    "    union = prediction_binary + target\n",
    "    union[union > 1] = 1\n",
    "    union = torch.sum(union)\n",
    "\n",
    "    dice = (intersection + smooth) / (union + smooth)\n",
    "    return dice.cpu().detach()\n",
    "\n",
    "def iou_score(model, dataset, threshold=0.5, device=\"cuda\", norm=1):\n",
    "    score_sum = 0\n",
    "    count = 0\n",
    "    with torch.inference_mode():\n",
    "        for i, data in enumerate(dataset):\n",
    "            input, target = data\n",
    "            input, target = input.to(device), [torch.tensor(t).to(device) for t in target]\n",
    "            model.resetState()\n",
    "                \n",
    "            prediction = model(input.unsqueeze(dim=0))\n",
    "            \n",
    "            for t in target:\n",
    "                score_sum += float(iou(prediction.squeeze(), t/norm, threshold))\n",
    "                prediction = model(input.unsqueeze(dim=0))\n",
    "                count += 1\n",
    "                \n",
    "            print(f\"{i:4d}/{len(dataset)}\", end=\"\\r\")\n",
    "\n",
    "    return score_sum/count\n",
    "\n",
    "def binary_dice_coefficient(prediction, target, threshold=0.5, smooth=1e-5):\n",
    "    prediction_binary = (prediction > threshold).float()\n",
    "    \n",
    "    intersection = torch.sum(prediction_binary * target)\n",
    "    union = torch.sum(prediction_binary) + torch.sum(target)\n",
    "\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return dice.cpu().detach()\n",
    "\n",
    "\n",
    "def dice_score(model, dataset, threshold=0.5, device=\"cuda\", norm=1):\n",
    "    score_sum = 0\n",
    "    count = 0\n",
    "    with torch.inference_mode():\n",
    "        for i, data in enumerate(dataset):\n",
    "            input, target = data\n",
    "            input, target = input.to(device), [torch.tensor(t).to(device) for t in target]\n",
    "            \n",
    "            model.resetState()\n",
    "            \n",
    "            prediction = model(input.unsqueeze(dim=0))\n",
    "            \n",
    "            for t in target:\n",
    "                score_sum += float(binary_dice_coefficient(prediction.squeeze(), t/norm, threshold))\n",
    "                prediction = model(input.unsqueeze(dim=0))\n",
    "                count += 1\n",
    "            \n",
    "            print(f\"{i:4d}/{len(dataset)}\", end=\"\\r\")\n",
    "\n",
    "    return score_sum/count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    dataset: Data, \n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer, \n",
    "    loss: torch.nn.Module, \n",
    "    writer: SummaryWriter,\n",
    "    n_epochs: tuple=(0, 50),\n",
    "    device: str=\"cuda\",\n",
    "    dice: bool=False,\n",
    "    norm: float=1.0,\n",
    "    log: Discord=None):\n",
    "    \n",
    "    for epoch in range(*n_epochs):\n",
    "        epoch_loss = 0\n",
    "        for data in dataset.train:\n",
    "            # reset hidden state\n",
    "            model.resetState()\n",
    "            \n",
    "            image, annotation = data\n",
    "            image = image.to(device).unsqueeze(dim=0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(image)\n",
    "            \n",
    "            l = 0\n",
    "        \n",
    "            for weight, ann in enumerate(annotation):\n",
    "                ann = torch.tensor(ann).to(\"cuda\").unsqueeze(dim=0).unsqueeze(dim=0).float()/norm\n",
    "                l += loss(output, ann)\n",
    "                # next step input                \n",
    "                output = model(image)\n",
    "            \n",
    "            l.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "        \n",
    "            epoch_loss += float(l)\n",
    "            \n",
    "        epoch_loss /= len(dataset.train)\n",
    "        writer.add_scalar(\"Loss/train\", epoch_loss, epoch)\n",
    "        print(f\"Epoch {epoch}: {epoch_loss}\")\n",
    "            \n",
    "        # val\n",
    "        with torch.inference_mode():\n",
    "            val_loss = 0\n",
    "            for data in dataset.val:\n",
    "                # reset hidden state\n",
    "                model.resetState()\n",
    "                \n",
    "                image, annotation = data\n",
    "                image = image.to(device).unsqueeze(dim=0)\n",
    "                \n",
    "                output = model(image)\n",
    "                \n",
    "                l = 0\n",
    "            \n",
    "                for weight, ann in enumerate(annotation):\n",
    "                    ann = torch.tensor(ann).to(\"cuda\").unsqueeze(dim=0).unsqueeze(dim=0).float()/norm\n",
    "                    l += loss(output, ann)\n",
    "                    # next step input                \n",
    "                    output = model(image)\n",
    "                    \n",
    "                val_loss += float(l)\n",
    "                \n",
    "            val_loss /= len(dataset.val)\n",
    "            writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "            writer.add_scalar(\"GradNorm\", model.grad_norm(), epoch)\n",
    "            \n",
    "            if log and epoch%50==0:\n",
    "                log.post(content=f\"Train loss: {float(epoch_loss)}, Val loss:{float(val_loss)}\")\n",
    "            \n",
    "    if not dice:\n",
    "        return\n",
    "    \n",
    "    dices = []\n",
    "    ious = []\n",
    "    for i, thresh in enumerate(np.arange(0, 1.1, 0.1)):\n",
    "        train_dice = dice_score(model, dataset.train, thresh)\n",
    "        val_dice = dice_score(model, dataset.val, thresh)\n",
    "        writer.add_scalar(\"Dice/train\", train_dice, i)\n",
    "        writer.add_scalar(\"Dice/val\", val_dice, i)\n",
    "        dices.append(train_dice)\n",
    "        \n",
    "        train_iou = iou_score(model, dataset.train, thresh)\n",
    "        val_iou = iou_score(model, dataset.val, thresh)\n",
    "        writer.add_scalar(\"IoU/train\", train_iou, i)\n",
    "        writer.add_scalar(\"IoU/val\", val_iou, i)\n",
    "        ious.append(train_iou)\n",
    "        \n",
    "    return dices, ious\n",
    "            \n",
    "def n_params(model):\n",
    "    return sum(param.numel() for param in model.parameters() if param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(model, dataset, idx, in_channels=3, height=200, width=200):\n",
    "    with torch.inference_mode():\n",
    "        image, annotation = dataset[idx]\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        plt.subplot(1, 7, 1)\n",
    "        plt.imshow(image.permute(1,2,0))\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        image = (image).unsqueeze(dim=0).to(\"cuda\")\n",
    "        \n",
    "        model.hidden = torch.ones(1, in_channels, height, width).to(\"cuda\")\n",
    "        for i in range(5):\n",
    "            plt.subplot(1, 7, i+2)\n",
    "            output = model(image)\n",
    "            \n",
    "            plt.imshow(output.detach().cpu().squeeze())\n",
    "            # plt.imshow(annotation[i])\n",
    "            plt.axis(\"off\")\n",
    "            \n",
    "        plt.savefig(\"fig.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = Discord(url=\"https://discord.com/api/webhooks/1219933822351577088/Gz4O9UZlnG7QBGTb9v5wPKlzxO3N8y_r9efsjFMOuHRki_Ok0Xw7e47P2eLt0A7DeA11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchy_score(model, dataset, threshold=0.5, device=\"cuda\", norm=1):\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    count = 0\n",
    "    with torch.inference_mode():\n",
    "        for i, data in enumerate(dataset):\n",
    "            input, target = data\n",
    "            input, target = input.to(device), [torch.tensor(t).to(device) for t in target]\n",
    "            \n",
    "            model.resetState()\n",
    "            \n",
    "            prediction = model(input.unsqueeze(dim=0))\n",
    "            \n",
    "            for t in target:\n",
    "                t_in = t.cpu().numpy()\n",
    "                pred_in = prediction.squeeze().cpu().numpy() >= threshold\n",
    "                \n",
    "                his_metrics = his.metrics.hierarchical_metrics(t_in, pred_in)\n",
    "                precision += his_metrics[\"precision\"]\n",
    "                recall += his_metrics[\"recall\"]\n",
    "                f1 += his_metrics[\"f1\"]\n",
    "                prediction = model(input.unsqueeze(dim=0))\n",
    "                count += 1\n",
    "            \n",
    "            print(f\"{i:4d}/{len(dataset)}\", end=\"\\r\")\n",
    "\n",
    "    return precision/count, recall/count, f1/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def get_datetime():\n",
    "    return datetime.datetime.now().strftime(\"%Y-%m-%d %I:%M:%S %p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 3.569179330468178\n",
      "fin RNN-2C, dRP500\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "\n",
    "# get combination of datasets and models\n",
    "for i, (model_def, dataset) in enumerate(product(MODELS, DATASETS)):\n",
    "    \n",
    "    # initialize model trainers\n",
    "    # -------log-----------\n",
    "    # log.post(content=f\"Training model {model_def.name}, {dataset.name} {get_datetime()}⭐\")\n",
    "    # -------log-----------\n",
    "    \n",
    "    model = model_def.init().cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    loss = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor(4.).cuda())\n",
    "    writer = SummaryWriter(f\"./runs/{model_def.name}_{dataset.name}\", comment=\"BCE_pos=4.0\")\n",
    "    \n",
    "    # training\n",
    "    dices, ious = train(dataset,\n",
    "      model,\n",
    "      optimizer,\n",
    "      loss,\n",
    "      writer,\n",
    "      n_epochs=(0, n_epochs),\n",
    "      dice=True,\n",
    "      log=log)\n",
    "    \n",
    "    size = dataset.val[0][1][0].shape[0]\n",
    "    show_results(model, dataset.val, 10, height=size, width=size)\n",
    "    # -------log-----------\n",
    "    # with open(\"fig.png\", \"rb\") as f:\n",
    "    #   log.post(content=f\"Result of {model_def.name} on {dataset.name}\", file={\n",
    "    #     \"output.png\": f\n",
    "    #   })\n",
    "    # -------log-----------\n",
    "    \n",
    "    # computing hierarchy metrics for scores\n",
    "    # threshold = np.argmax(ious)/10\n",
    "    # h_train = hierarchy_score(model, dataset.train, threshold)\n",
    "    # h_val = hierarchy_score(model, dataset.val, threshold)\n",
    "    # writer.add_scalar(\"HIS/Precision/train\", h_train[0])\n",
    "    # writer.add_scalar(\"HIS/Recall/train\", h_train[1])\n",
    "    # writer.add_scalar(\"HIS/F1/train\", h_train[2])\n",
    "    # writer.add_scalar(\"HIS/Precision/val\", h_val[0])\n",
    "    # writer.add_scalar(\"HIS/Recall/val\", h_val[1])\n",
    "    # writer.add_scalar(\"HIS/F1/train\", h_val[2])\n",
    "    \n",
    "    # -------log-----------\n",
    "    # log.post(content=f\"Training:\\n Precision: {h_train[0]}, Recall: {h_train[1]}, F1: {h_train[2]}\")\n",
    "    # log.post(content=f\"Validation:\\n Precision: {h_val[0]}, Recall: {h_val[1]}, F1: {h_val[2]}\")\n",
    "    # log.post(content=f\"Training finished {get_datetime()} ✅\")\n",
    "    # -------log-----------\n",
    "    print(f\"fin {model_def.name}, {dataset.name}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Callable\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# %%\n",
    "def find_seed(matrix: np.ndarray) -> Tuple[int, int]:\n",
    "    \"\"\"finds first non-zero entry in the matrix\n",
    "\n",
    "    Args:\n",
    "        matrix (np.ndarray): 2-D matrix of binary non overlapping regions\n",
    "\n",
    "    Returns:\n",
    "        Tuple[int, int]: index of first non-zero entry\n",
    "    \"\"\"\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            if matrix[i, j] == 1:\n",
    "                return i, j\n",
    "\n",
    "# %%\n",
    "def flood(mask: np.ndarray, \n",
    "          seed_x: int,\n",
    "          seed_y: int,\n",
    "          value: int = 2) -> None:\n",
    "    \"\"\"flood fills the area for given seed\n",
    "\n",
    "    Args:\n",
    "        mask (np.ndarray): 2-D matrix with regions\n",
    "        seed_x (int): x index of seed\n",
    "        seed_y (int): y index of seed\n",
    "        value (int, optional): fill value. Defaults to 2.\n",
    "    \"\"\"\n",
    "    flood_area = mask[seed_x, seed_y]\n",
    "    fill_pixels = [(seed_x, seed_y)]\n",
    "    \n",
    "    # track visited pixels\n",
    "    filled = np.zeros_like(mask)\n",
    "    filled[seed_x, seed_y] = 1\n",
    "    \n",
    "    def is_valid(i, j):\n",
    "        return (i >= 0\n",
    "                and j >= 0\n",
    "                and i < mask.shape[0]\n",
    "                and j < mask.shape[1])\n",
    "    \n",
    "    while fill_pixels:\n",
    "        x, y = fill_pixels.pop()    \n",
    "        mask[x, y] = value\n",
    "        \n",
    "        for dx, dy in itertools.product([0,1,-1], [0, 1, -1]):\n",
    "            if (is_valid(x+dx, y+dy) \n",
    "                and mask[x+dx, y+dy] == flood_area \n",
    "                and filled[x+dx, y+dy] == 0):\n",
    "                fill_pixels.append((x+dx, y+dy))\n",
    "                filled[x+dx, y+dy] = 1\n",
    "                    \n",
    "\n",
    "# %%\n",
    "def flood_fill(mask: np.ndarray) -> int:\n",
    "    index = find_seed(mask)\n",
    "    mask_counter = 2\n",
    "    while index:\n",
    "        flood(mask, index[0], index[1], mask_counter)\n",
    "        index = find_seed(mask)\n",
    "        mask_counter += 1\n",
    "    return mask, mask_counter-2\n",
    "\n",
    "# %%\n",
    "def binary_mask_to_children(mask: np.ndarray) -> List[np.ndarray]:\n",
    "    \"\"\"Converts a compund binary mask to list of individual masks\n",
    "\n",
    "    Args:\n",
    "        mask (torch.tensor): binary mask of objects\n",
    "    \"\"\"\n",
    "    \n",
    "    mask, n_children = flood_fill(mask.copy())\n",
    "        \n",
    "    children = []\n",
    "    for i in range(n_children):\n",
    "        children.append(mask == i+2)\n",
    "        \n",
    "    return children\n",
    "\n",
    "# %%\n",
    "class Tree:\n",
    "    def __init__(self, data, level=0):\n",
    "        self.data = data\n",
    "        self.level = level\n",
    "        self.entropy = 1\n",
    "        self.children: List[Tree] = []\n",
    "        self.match = None\n",
    "        \n",
    "    def traverse_inorder(self, func: Callable=lambda x, l: print(\"  \"*l, x.data)):\n",
    "        func(self, self.level)\n",
    "        for child in self.children:\n",
    "            child.traverse_inorder(func)\n",
    "            \n",
    "    def _assign_r_entropy(self, entropy=1):\n",
    "        self.entropy = (2*entropy)/(len(self.children)+2) if len(self.children) else entropy\n",
    "        for child in self.children:\n",
    "            child._assign_r_entropy(entropy/(len(self.children)+2))\n",
    "            \n",
    "    def assign_entropy(self):\n",
    "        self._assign_r_entropy()\n",
    "        def reciprocal(x, l):\n",
    "            x.entropy = 1/x.entropy\n",
    "            \n",
    "        self.traverse_inorder(reciprocal)\n",
    "        \n",
    "    def total_entropy(self):\n",
    "        total = 0\n",
    "        def get_total(x, l):\n",
    "            nonlocal total\n",
    "            total += x.entropy\n",
    "            \n",
    "        self.traverse_inorder(get_total)\n",
    "        return total\n",
    "    \n",
    "    def copy(self):\n",
    "        root = Tree(self.data, self.level)\n",
    "        \n",
    "        for child in self.children:\n",
    "            root.children.append(child.copy())\n",
    "        \n",
    "        return root\n",
    "    \n",
    "    def find_matching(self, masks: np.ndarray, threshold=0.9) -> \"Tree\":\n",
    "        tree = self.copy()\n",
    "        \n",
    "        def matcher(x, l):\n",
    "            for m in masks:\n",
    "                if np.sum(x.data & m) / np.sum(x.data | m) >= threshold:\n",
    "                    x.match = True\n",
    "                    \n",
    "        tree.traverse_inorder(matcher)\n",
    "        return tree\n",
    "    \n",
    "    def _flat_list(self) -> List[\"Tree\"]:\n",
    "        children = []\n",
    "        for child in self.children:\n",
    "            if child.match == True:\n",
    "                children.append(child)\n",
    "            else:\n",
    "                children.extend(child._flat_list())\n",
    "                \n",
    "        return children\n",
    "        \n",
    "        \n",
    "    def prune(self, level=0):\n",
    "        root = Tree(self.data, level)\n",
    "        children = self._flat_list()\n",
    "        \n",
    "        for child in children:\n",
    "            root.children.append(child.prune(level+1))\n",
    "            \n",
    "        return root\n",
    "        \n",
    "# %%\n",
    "def is_contained(parent: np.ndarray, child: np.ndarray):\n",
    "    return np.all((parent & child) == child)\n",
    "\n",
    "# %%\n",
    "def _generate_tree(root: Tree, mask_groups: dict):\n",
    "    if root.level + 1 > len(mask_groups):\n",
    "        return\n",
    "    \n",
    "    for mask in mask_groups[root.level+1]:\n",
    "        if is_contained(root.data, mask):\n",
    "            root.children.append(Tree(mask, root.level+1))\n",
    "            \n",
    "    for child in root.children:\n",
    "        _generate_tree(child, mask_groups)\n",
    "\n",
    "# %%\n",
    "def generate_mask_tree(masks: List[np.ndarray]) -> Tree:\n",
    "    root = Tree(np.ones(masks[0].shape, dtype=bool))\n",
    "    mask_groups = {i+1: binary_mask_to_children(mask) for i, mask in enumerate(masks)}\n",
    "    \n",
    "    # generate mask hierarchy tree\n",
    "    _generate_tree(root, mask_groups)\n",
    "    \n",
    "    return root\n",
    "\n",
    "# %%\n",
    "def get_mask_list(masks: List[np.ndarray]) -> List[np.ndarray]:\n",
    "    mask_list = []\n",
    "    for mask in masks:\n",
    "        mask_list.extend(binary_mask_to_children(mask))\n",
    "        \n",
    "    return mask_list\n",
    "\n",
    "# %%\n",
    "def hierarchical_metrics(truth: List[np.ndarray], pred: List[np.ndarray]) -> dict:\n",
    "    \n",
    "    print(f\"truth: {len(truth)}, pred: {len(pred)}\")\n",
    "    \n",
    "    # ground truth tree\n",
    "    gt_tree = generate_mask_tree(truth)\n",
    "    \n",
    "    print(f\"generated gt tree\")\n",
    "    \n",
    "    # prediction list\n",
    "    pred_tree = generate_mask_tree(pred)\n",
    "    print(f\"generated pred tree\")\n",
    "    \n",
    "    preds = get_mask_list(pred)\n",
    "    \n",
    "    # get matching tree\n",
    "    pruned_tree = gt_tree.find_matching(preds).prune()\n",
    "    \n",
    "    # assign entropy\n",
    "    gt_tree.assign_entropy()\n",
    "    pred_tree.assign_entropy()\n",
    "    pruned_tree.assign_entropy()\n",
    "    \n",
    "    gt_tree.traverse_inorder(lambda x, l: print(\"  \"*l, x.entropy))\n",
    "    pred_tree.traverse_inorder(lambda x, l: print(\"  \"*l, x.entropy))\n",
    "    pruned_tree.traverse_inorder(lambda x, l: print(\"  \"*l, x.entropy))\n",
    "    \n",
    "    # compute entropy\n",
    "    gt_e = gt_tree.total_entropy()\n",
    "    pred_e = pred_tree.total_entropy()\n",
    "    pruned_e = pruned_tree.total_entropy()\n",
    "    \n",
    "    # precision, recall , f1\n",
    "    precision = pruned_e / pred_e\n",
    "    recall = pruned_e / gt_e\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return {\n",
    "        \"hierarchical-precision\": precision,\n",
    "        \"hierarchical-recall\": recall,\n",
    "        \"hierarchical-f1\": f1\n",
    "    }\n",
    "\n",
    "def hierarchy_score(model, dataset, threshold=0.5, device=\"cuda\", norm=1):\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    count = 0\n",
    "    with torch.inference_mode():\n",
    "        for i, data in enumerate(dataset):\n",
    "            input, target = data\n",
    "            input, target = input.to(device), [torch.tensor(t).to(device) for t in target]\n",
    "            \n",
    "            model.resetState()\n",
    "            \n",
    "            prediction = model(input.unsqueeze(dim=0))\n",
    "            t_in = []\n",
    "            pred_in = []\n",
    "            for t in target[:-1]:\n",
    "                t_in.append(t.cpu().numpy())\n",
    "                pred_in.append((prediction.squeeze().cpu().numpy() >= threshold).astype(int))\n",
    "                prediction = model(input.unsqueeze(dim=0))\n",
    "                count += 1\n",
    "                \n",
    "            his_metrics = hierarchical_metrics(t_in, pred_in)\n",
    "            precision += his_metrics[\"hierarchical-precision\"]\n",
    "            recall += his_metrics[\"hierarchical-recall\"]\n",
    "            f1 += his_metrics[\"hierarchical-f1\"]\n",
    "            \n",
    "            print(f\"{i:4d}/{len(dataset)}\", end=\"\\r\")\n",
    "\n",
    "    return precision/count, recall/count, f1/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f40dcdef6d0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGhCAYAAADbf0s2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAm2UlEQVR4nO3df3SU9YHv8c+TXwOkyWgIZDIyxNRCrYSb8kNBbCVQiUT5JVRAPG04Klsrss0FVmW9Ltj1GrVHrVdW1/YoYqUX2nsFbWHVIARk0S0EsIBeDBpM0MQsHJhJAkx+fe8frFPHhITAJPNN8n6d85zDfJ/vPHzmmzn55Jl5MnGMMUYAAFgoJtoBAAA4F0oKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgraiW1HPPPafMzEz16dNHo0aN0rvvvhvNOAAAy0StpNatW6eCggI9+OCD2rt3r374wx8qLy9P5eXl0YoEALCME60PmB0zZoxGjhyp559/PjT2ve99TzNmzFBhYWGb921ubtYXX3yhpKQkOY7T2VEBABFmjFFNTY28Xq9iYs59vhTXhZlC6uvrVVJSogceeCBsPDc3Vzt37mwxPxgMKhgMhm5//vnnuuqqqzo9JwCgc1VUVGjQoEHn3B+Vkjp27JiampqUlpYWNp6WlqaqqqoW8wsLC/Xwww+3GP+BblKc4jstJwCgczSqQTu0SUlJSW3Oi0pJfeWbL9UZY1p9+W7ZsmVavHhx6HYgEJDP51Oc4hXnUFIA0O381xtN7b1lE5WSSk1NVWxsbIuzpurq6hZnV5Lkcrnkcrm6Kh4AwBJRubovISFBo0aNUlFRUdh4UVGRxo0bF41IAAALRe3lvsWLF+snP/mJRo8erWuvvVa/+c1vVF5errvvvjtakQAAlolaSc2ZM0fHjx/XL3/5S1VWViorK0ubNm1SRkZGtCIBACwTtd+TuhiBQEBut1s5ms6FEwDQDTWaBhXrdfn9fiUnJ59zHp/dBwCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALBWxEuqsLBQV199tZKSkjRw4EDNmDFDhw4dCpszf/58OY4Tto0dOzbSUQAA3VzES2rbtm1auHCh3n//fRUVFamxsVG5ubmqq6sLmzd58mRVVlaGtk2bNkU6CgCgm4uL9AHffPPNsNurVq3SwIEDVVJSouuvvz407nK55PF4Iv3fAwB6kE5/T8rv90uSUlJSwsaLi4s1cOBADR06VAsWLFB1dfU5jxEMBhUIBMI2AEDP16klZYzR4sWL9YMf/EBZWVmh8by8PK1Zs0ZbtmzRk08+qV27dmnixIkKBoOtHqewsFButzu0+Xy+zowNALCEY4wxnXXwhQsXauPGjdqxY4cGDRp0znmVlZXKyMjQ2rVrNXPmzBb7g8FgWIEFAgH5fD7laLrinPhOyQ4A6DyNpkHFel1+v1/JycnnnBfx96S+smjRIr3xxhvavn17mwUlSenp6crIyFBpaWmr+10ul1wuV2fEBABYLOIlZYzRokWLtH79ehUXFyszM7Pd+xw/flwVFRVKT0+PdBwAQDcW8fekFi5cqFdffVW///3vlZSUpKqqKlVVVen06dOSpNraWi1dulTvvfeejhw5ouLiYk2dOlWpqam65ZZbIh0HANCNRfxM6vnnn5ck5eTkhI2vWrVK8+fPV2xsrPbv369XXnlFJ0+eVHp6uiZMmKB169YpKSkp0nEAAN1Yp7zc15a+ffvqrbfeivR/CwDogfjsPgCAtSgpAIC1KCkAgLUoKQCAtSgpAIC1KCkAgLUoKQCAtSgpAIC1KCkAgLUoKQCAtSgpAIC1KCkAgLUoKQCAtSgpAIC1KCkAgLUoKQCAtSgpAIC1KCkAgLUoKQCAtSgpAIC14qIdAED3ENOvn+rHfk+xwSY57+2XmpuiHQm9AGdSAM6Lk3GZZjy7WalPfKZYd3K046CX4EwKwHlxak/r13smypxI0HfrD0Q7DnoJSgrAeWmsOKrv5FdKplnNxkQ7DnoJSgrA+eN9KHQx3pMCAFiLkgLQppjERJU9eq1Knx2juHRPtOOgl6Gk0O05cXFyXK7Qhshy+vbRhBv26Z8mrZe5JCnacdDL8J4Uur0j/3S1vnP9EUlSxclLdNk/BNVU+ml0Q/Ugzf4aHVqerQ/7/Dd9q5yr+tC1KCl0b46j+suDeiRjg74Tb/QfwUT9KnlutFP1KKahXq5/2yVJao5yFvQ+vNyH7s0YXfk/A1r8s4X65/8cG+00ACKMMyl0e02HDst1NFF//nSYjl32LcWcaRQXSgM9AyWFHqG5rk6X33tcVXGXqLnyk2jHARAhlBR6jMbKqmhHABBhvCcFALBWxEtqxYoVchwnbPN4/vYLgMYYrVixQl6vV3379lVOTo4OHjwY6RgAgB6gU86khg0bpsrKytC2f//+0L4nnnhCTz31lFauXKldu3bJ4/Fo0qRJqqmp6YwoAIBurFNKKi4uTh6PJ7QNGDBA0tmzqF//+td68MEHNXPmTGVlZWn16tU6deqUfv/733dGFABAN9YpJVVaWiqv16vMzEzNnTtXn3569rf/y8rKVFVVpdzc3NBcl8ul8ePHa+fOnec8XjAYVCAQCNsAAD1fxEtqzJgxeuWVV/TWW2/pt7/9raqqqjRu3DgdP35cVVVnr75KS0sLu09aWlpoX2sKCwvldrtDm8/ni3RsAICFIl5SeXl5mjVrloYPH64bbrhBGzdulCStXr06NMdxnLD7GGNajH3dsmXL5Pf7Q1tFRUWkYwMALNTpl6AnJiZq+PDhKi0tDV3l982zpurq6hZnV1/ncrmUnJwctgEAer5OL6lgMKiPPvpI6enpyszMlMfjUVFRUWh/fX29tm3bpnHjxnV2FABANxPxT5xYunSppk6dqsGDB6u6ulqPPPKIAoGA8vPz5TiOCgoK9Oijj2rIkCEaMmSIHn30UfXr10/z5s2LdBQAQDcX8ZI6evSobrvtNh07dkwDBgzQ2LFj9f777ysjI0OSdN999+n06dO65557dOLECY0ZM0Zvv/22kpL4Y2oAgHCOMcZEO0RHBQIBud1u5Wi64pz4aMcBAHRQo2lQsV6X3+9v8zoDPrsPAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgpAu2L69VNMYqLkONGOgl6GkgLQptjkZH38m+/q2LrLFJfhi3Yc9DJx0Q4AoHPEJCXJSUsN3TZfHlNzTU3HD5QQrxnf+0Djkg7rxX6TI5gQaB8lBfRQ/zk7S3+39HXFqllNitFvn5iulFXvRTsW0CGUFNBDxTRKn9dfqhgZNctRTNMFHqixUW999j0dvCRdsWfqI5oRaE/E35O6/PLL5ThOi23hwoWSpPnz57fYN3bs2EjHAHq9/uv2avdkn/4yebB2T/Yp5Q97L+g4Tf6ABv9dlWLm1KvxSEWEUwJti/iZ1K5du9TU9Lcf2Q4cOKBJkybp1ltvDY1NnjxZq1atCt1OSEiIdAyg12s+c0bNlVUXfRwnLl6nxnxbjX1ilPT2mQt7Xwu4QBEvqQEDBoTdfuyxx3TFFVdo/PjxoTGXyyWPx3PexwwGgwoGg6HbgUDg4oMCOC8x7iRdtWK/xiYd1toPJ0gfUVLoOp16CXp9fb1effVV3XHHHXK+9vsVxcXFGjhwoIYOHaoFCxaourq6zeMUFhbK7XaHNp+Py2CBrmJOn9E7b43Qw2/+WM5JCgpdyzHGmM46+B/+8AfNmzdP5eXl8nq9kqR169bpW9/6ljIyMlRWVqaHHnpIjY2NKikpkcvlavU4rZ1J+Xw+5Wi64pz4zooPAOgkjaZBxXpdfr9fycnJ55zXqSV14403KiEhQX/605/OOaeyslIZGRlau3atZs6ceV7HDQQCcrvdlBS6jBMXp88LrtGpQc268n9VqfHTI9GOBHRr51tSnfZy32effabNmzfrrrvuanNeenq6MjIyVFpa2llRgIsXGyvfzUf0f6c/o3rvJdFOA/QanVZSq1at0sCBA3XzzTe3Oe/48eOqqKhQenp6Z0UBAHRTnVJSzc3NWrVqlfLz8xUX97cLCGtra7V06VK99957OnLkiIqLizV16lSlpqbqlltu6YwoACIg9hK3Yi+9lA+YRZfrlJLavHmzysvLdccdd4SNx8bGav/+/Zo+fbqGDh2q/Px8DR06VO+9956SkpI6IwqAixR7iVufvJChU+vcirt8cLTjoJfplI9Fys3NVWvXY/Tt21dvvfVWZ/yXADpLXJymfOfA2Q+Y7csHzKJr8ac6AADWoqQAANaipAAA1qKkAADWoqQAANaipAAA1qKkAADWoqQAANaipAAA1qKkAADWoqQAANaipAAA1qKkAADWoqQAANaipAAA1qKkAADWoqQAANaipAAA1qKkAADWoqQAANaipAAA1qKkAADWoqQAANaipAAA1qKkAADWoqQAANaipAAA1qKkAADWoqQAANaKi3YAAHYzp8/oz/82Rhu+dY2uPHEk2nHQy1BSANrUXFeny//He5KkxihnQe9DSQFoU0y/fjqy9PtqTDQa+vSnaqz6MtqR0IvwnhSANjn9+upHU0v0zzPWylyaHO046GU4kwLQpmZ/jT4oHKES1whd+vmH0Y6DXoaSAs7TiTN99XHDQDnNJtpRupRpqFe/1/5DktQU5SzofTr8ct/27ds1depUeb1eOY6jDRs2hO03xmjFihXyer3q27evcnJydPDgwbA5wWBQixYtUmpqqhITEzVt2jQdPXr0oh4I0JlMfb3cD/XVC3f/WHEHyqIdB+g1OlxSdXV1ys7O1sqVK1vd/8QTT+ipp57SypUrtWvXLnk8Hk2aNEk1NTWhOQUFBVq/fr3Wrl2rHTt2qLa2VlOmTFFTEz+nwVLGyOw+oLgtJWoKBKKdBug1HGPMBb924TiO1q9frxkzZkg6exbl9XpVUFCg+++/X9LZs6a0tDQ9/vjj+tnPfia/368BAwbod7/7nebMmSNJ+uKLL+Tz+bRp0ybdeOONLf6fYDCoYDAYuh0IBOTz+ZSj6Ypz4i80PgAgShpNg4r1uvx+v5KTz31BTkSv7isrK1NVVZVyc3NDYy6XS+PHj9fOnTslSSUlJWpoaAib4/V6lZWVFZrzTYWFhXK73aHN5/NFMjYAwFIRLamqqipJUlpaWth4WlpaaF9VVZUSEhJ06aWXnnPONy1btkx+vz+0VVRURDI2AMBSnXJ1n+M4YbeNMS3GvqmtOS6XSy6XK2L5AADdQ0TPpDwejyS1OCOqrq4OnV15PB7V19frxIkT55wDAIAU4TOpzMxMeTweFRUVacSIEZKk+vp6bdu2TY8//rgkadSoUYqPj1dRUZFmz54tSaqsrNSBAwf0xBNPRDIOEBE1c8bqWHb4Wb7rhCPfbw+q6aQ/bPzMlGtUOS5WkhTTKH37fx9T00elXZb1YjXljFR5rkuDttQrfnNJtOMAHS+p2tpaHT58OHS7rKxM+/btU0pKigYPHqyCggI9+uijGjJkiIYMGaJHH31U/fr107x58yRJbrdbd955p5YsWaL+/fsrJSVFS5cu1fDhw3XDDTdE7pEBEVI9LajDE1aFjf3G79Xr/+dq6RsldfSGGH0y+/mz92uq06y9i9Xvoy6LetG+uK6PPp7/nL7b9HNdvjnaaYALKKndu3drwoQJoduLFy+WJOXn5+vll1/Wfffdp9OnT+uee+7RiRMnNGbMGL399ttKSkoK3efpp59WXFycZs+erdOnT+tHP/qRXn75ZcXGxkbgIQGRddnaeA07cE/YmOukUdqxAy3mXv6nBg378uzcmEbJt7+yW31Kw6AtdRrWfI8G7zgd7SiApIv8PaloCQQCcrvd/J4UAHRTUfk9KQAAIomSAgBYi5ICAFiLkgIAWIuSAgBYi5ICAFiLkgIAWIuSAgBYi5ICAFiLkgIAWIuSAgBYi5ICAFiLkgIAWIuSAgBYi5ICAFiLkgIAWIuSAgBYi5ICAFiLkgIAWIuSAgBYi5ICAFiLkgIAWIuSAgBYi5ICAFiLkgIAWIuSAgBYi5ICAFiLkgIAWIuSAgBYi5ICAFiLkgIAWIuSAgBYi5ICAFiLkgIAWIuSAgBYq8MltX37dk2dOlVer1eO42jDhg2hfQ0NDbr//vs1fPhwJSYmyuv16qc//am++OKLsGPk5OTIcZywbe7cuRf9YAAAPUuHS6qurk7Z2dlauXJli32nTp3Snj179NBDD2nPnj167bXX9PHHH2vatGkt5i5YsECVlZWh7YUXXriwRwAA6LHiOnqHvLw85eXltbrP7XarqKgobOzZZ5/VNddco/Lycg0ePDg03q9fP3k8no7+9wCAXqTT35Py+/1yHEeXXHJJ2PiaNWuUmpqqYcOGaenSpaqpqTnnMYLBoAKBQNgGAOj5Onwm1RFnzpzRAw88oHnz5ik5OTk0fvvttyszM1Mej0cHDhzQsmXL9MEHH7Q4C/tKYWGhHn744c6MCgCwkGOMMRd8Z8fR+vXrNWPGjBb7GhoadOutt6q8vFzFxcVhJfVNJSUlGj16tEpKSjRy5MgW+4PBoILBYOh2IBCQz+dTjqYrzom/0PgAgChpNA0q1uvy+/1t9kOnnEk1NDRo9uzZKisr05YtW9oMIEkjR45UfHy8SktLWy0pl8sll8vVGVEBABaLeEl9VVClpaXaunWr+vfv3+59Dh48qIaGBqWnp0c6DoAIiUlM1OnxVyn2TLPit38g09h4zrmOy6X68cNVnxQrSepzvEGx2z+Qmpu6Ki56iA6XVG1trQ4fPhy6XVZWpn379iklJUVer1c//vGPtWfPHv35z39WU1OTqqqqJEkpKSlKSEjQJ598ojVr1uimm25SamqqPvzwQy1ZskQjRozQddddF7lHBiCinIzL9JMn/6Qd/iH6Mi9JTSdOnHNubGp/Xf34bv1D6r9Lku74dJYabuqj5rq6roqLHqLDJbV7925NmDAhdHvx4sWSpPz8fK1YsUJvvPGGJOn73/9+2P22bt2qnJwcJSQk6J133tEzzzyj2tpa+Xw+3XzzzVq+fLliY2Mv4qEA6EyOv1aPbJ+qOH+cvlP/1zbnmlOn9cftY/Wny7IkSU2HkpTZuKcrYqKHuagLJ6IlEAjI7XZz4QQAdFNRvXACQO/kxMXpy7uvUeA7zZIk1/EYXb7yozZfGgTaQkkBiJzYWKXPOqK9390kSfqN36vXX71aoqRwgfgUdACAtTiTAhBRtfUuVTedvYrvWEOS1P3e9oZFKCkAEWPq69Xnl279eMB/lyTF1TbJVXUwyqnQnVFSACLHGDn/vk99vzbUHLUw6Al4TwoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgLUoKAGAtSgoAYC1KCgBgrQ6X1Pbt2zV16lR5vV45jqMNGzaE7Z8/f74cxwnbxo4dGzYnGAxq0aJFSk1NVWJioqZNm6ajR49e1AMBAPQ8HS6puro6ZWdna+XKleecM3nyZFVWVoa2TZs2he0vKCjQ+vXrtXbtWu3YsUO1tbWaMmWKmpqaOv4IAAA9VlxH75CXl6e8vLw257hcLnk8nlb3+f1+vfjii/rd736nG264QZL06quvyufzafPmzbrxxhs7GgkA0EN1yntSxcXFGjhwoIYOHaoFCxaouro6tK+kpEQNDQ3Kzc0NjXm9XmVlZWnnzp2tHi8YDCoQCIRtAICeL+IllZeXpzVr1mjLli168skntWvXLk2cOFHBYFCSVFVVpYSEBF166aVh90tLS1NVVVWrxywsLJTb7Q5tPp8v0rEBABbq8Mt97ZkzZ07o31lZWRo9erQyMjK0ceNGzZw585z3M8bIcZxW9y1btkyLFy8O3Q4EAhQVAPQCnX4Jenp6ujIyMlRaWipJ8ng8qq+v14kTJ8LmVVdXKy0trdVjuFwuJScnh20AgJ6v00vq+PHjqqioUHp6uiRp1KhRio+PV1FRUWhOZWWlDhw4oHHjxnV2HABAN9Lhl/tqa2t1+PDh0O2ysjLt27dPKSkpSklJ0YoVKzRr1iylp6fryJEj+sd//EelpqbqlltukSS53W7deeedWrJkifr376+UlBQtXbpUw4cPD13tBwCAdAEltXv3bk2YMCF0+6v3ivLz8/X8889r//79euWVV3Ty5Emlp6drwoQJWrdunZKSkkL3efrppxUXF6fZs2fr9OnT+tGPfqSXX35ZsbGxEXhIAICewjHGmGiH6KhAICC3260cTVecEx/tOACADmo0DSrW6/L7/W1eZ8Bn9wEArEVJAQCsRUkBAKxFSQEArEVJAQCsRUkBAKxFSQEArEVJAQCsRUkBAKxFSQEArEVJAQCsRUkBAKxFSQEArEVJAQCsRUkBAKxFSQEArEVJAQCsRUkBAKxFSQEArEVJAQCsRUkBAKxFSQEArEVJAQCsRUkBAKxFSQEArEVJAQCsRUkBAKxFSQEArEVJAQCsRUkBAKxFSQEArEVJAQCsRUkBAKxFSQEArEVJAQCs1eGS2r59u6ZOnSqv1yvHcbRhw4aw/Y7jtLr96le/Cs3JyclpsX/u3LkX/WAAAD1Lh0uqrq5O2dnZWrlyZav7Kysrw7aXXnpJjuNo1qxZYfMWLFgQNu+FF164sEcAAOix4jp6h7y8POXl5Z1zv8fjCbv9+uuva8KECfr2t78dNt6vX78WcwEA+LpOfU/qyy+/1MaNG3XnnXe22LdmzRqlpqZq2LBhWrp0qWpqas55nGAwqEAgELYBAHq+Dp9JdcTq1auVlJSkmTNnho3ffvvtyszMlMfj0YEDB7Rs2TJ98MEHKioqavU4hYWFevjhhzszKgDAQo4xxlzwnR1H69ev14wZM1rdf+WVV2rSpEl69tln2zxOSUmJRo8erZKSEo0cObLF/mAwqGAwGLodCATk8/mUo+mKc+IvND4AIEoaTYOK9br8fr+Sk5PPOa/TzqTeffddHTp0SOvWrWt37siRIxUfH6/S0tJWS8rlcsnlcnVGTACAxTrtPakXX3xRo0aNUnZ2drtzDx48qIaGBqWnp3dWHABAN9ThM6na2lodPnw4dLusrEz79u1TSkqKBg8eLOnsy3F//OMf9eSTT7a4/yeffKI1a9bopptuUmpqqj788EMtWbJEI0aM0HXXXXcRDwUA0NN0uKR2796tCRMmhG4vXrxYkpSfn6+XX35ZkrR27VoZY3Tbbbe1uH9CQoLeeecdPfPMM6qtrZXP59PNN9+s5cuXKzY29gIfBgCgJ7qoCyeiJRAIyO12c+EEAHRT53vhBJ/dBwCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsBYlBQCwFiUFALAWJQUAsFZctANEhOPIiY0N3TRNTZIxUQwEAPjqe/PFfE/uEWdSwbzROvnG5ar58+Cz2+wx0Y4EAL1eYO4Y1fx5sE7+ZOwFH6NHnEnV+OL0fvY6nTL1OtbUpFsG3aekaIcCgF6u1hejDd97RVMH36dLLvAYPaKkvvLD3Xeo//OJ8v2/CjVGOwwA9HKD/3BUd31QoMzSLy74e3K3LCnzX69tNqpBMlJT/RkFaprlL4vXgDff05ko5wMASI1lnyim7JNWvyc3qkHS376fn4tj2pthoaNHj8rn80U7BgDgIlVUVGjQoEHn3N8tS6q5uVmHDh3SVVddpYqKCiUnJ0c70nkLBALy+XzdLrfUfbOTu2uRu+t1x+zGGNXU1Mjr9Som5tzX8HXLl/tiYmJ02WWXSZKSk5O7zRfl67prbqn7Zid31yJ31+tu2d1ud7tzesQl6ACAnomSAgBYq9uWlMvl0vLly+VyuaIdpUO6a26p+2Ynd9cid9frztnb0y0vnAAA9A7d9kwKANDzUVIAAGtRUgAAa1FSAABrUVIAAGt125J67rnnlJmZqT59+mjUqFF69913ox0pTGFhoa6++molJSVp4MCBmjFjhg4dOhQ2Z/78+XIcJ2wbO/bC/+5KJKxYsaJFJo/HE9pvjNGKFSvk9XrVt29f5eTk6ODBg1FMfNbll1/eIrfjOFq4cKEke9Z6+/btmjp1qrxerxzH0YYNG8L2n8/6BoNBLVq0SKmpqUpMTNS0adN09OjRqGZvaGjQ/fffr+HDhysxMVFer1c//elP9cUXX4QdIycnp8XXYe7cuVHLLZ3fcyMaa95e7tae747j6Fe/+lVoTjTWO9K6ZUmtW7dOBQUFevDBB7V371798Ic/VF5ensrLy6MdLWTbtm1auHCh3n//fRUVFamxsVG5ubmqq6sLmzd58mRVVlaGtk2bNkUp8d8MGzYsLNP+/ftD+5544gk99dRTWrlypXbt2iWPx6NJkyappqYmiomlXbt2hWUuKiqSJN16662hOTasdV1dnbKzs7Vy5cpW95/P+hYUFGj9+vVau3atduzYodraWk2ZMkVNTU1Ry37q1Cnt2bNHDz30kPbs2aPXXntNH3/8saZNm9Zi7oIFC8K+Di+88ELUcn+lvedGNNa8vdxfz1tZWamXXnpJjuNo1qxZYfO6er0jznRD11xzjbn77rvDxq688krzwAMPRClR+6qrq40ks23bttBYfn6+mT59evRCtWL58uUmOzu71X3Nzc3G4/GYxx57LDR25swZ43a7zb/+6792UcLz84tf/MJcccUVprm52Rhj51pLMuvXrw/dPp/1PXnypImPjzdr164Nzfn8889NTEyMefPNN6OWvTV/+ctfjCTz2WefhcbGjx9vfvGLX3RuuDa0lru954YNa34+6z19+nQzceLEsLFor3ckdLszqfr6epWUlCg3NzdsPDc3Vzt37oxSqvb5/X5JUkpKSth4cXGxBg4cqKFDh2rBggWqrq6ORrwwpaWl8nq9yszM1Ny5c/Xpp59KksrKylRVVRW29i6XS+PHj7dq7evr6/Xqq6/qjjvukOM4oXEb1/rrzmd9S0pK1NDQEDbH6/UqKyvLqq+BdPY57ziOLrnkkrDxNWvWKDU1VcOGDdPSpUujfhYutf3c6A5r/uWXX2rjxo268847W+yzcb07ott9CvqxY8fU1NSktLS0sPG0tDRVVVVFKVXbjDFavHixfvCDHygrKys0npeXp1tvvVUZGRkqKyvTQw89pIkTJ6qkpCRqH28yZswYvfLKKxo6dKi+/PJLPfLIIxo3bpwOHjwYWt/W1v6zzz6LRtxWbdiwQSdPntT8+fNDYzau9Tedz/pWVVUpISFBl156aYs5Nj3/z5w5owceeEDz5s0L+1Tu22+/XZmZmfJ4PDpw4ICWLVumDz74IPTybDS099zoDmu+evVqJSUlaebMmWHjNq53R3W7kvrK139Cls4WwTfHbHHvvffqr3/9q3bs2BE2PmfOnNC/s7KyNHr0aGVkZGjjxo0tnmxdJS8vL/Tv4cOH69prr9UVV1yh1atXh95Mtn3tX3zxReXl5cnr9YbGbFzrc7mQ9bXpa9DQ0KC5c+equblZzz33XNi+BQsWhP6dlZWlIUOGaPTo0dqzZ49GjhzZ1VElXfhzw6Y1f+mll3T77berT58+YeM2rndHdbuX+1JTUxUbG9viJ5jq6uoWP4HaYNGiRXrjjTe0devWNv/6pCSlp6crIyNDpaWlXZSufYmJiRo+fLhKS0tDV/nZvPafffaZNm/erLvuuqvNeTau9fmsr8fjUX19vU6cOHHOOdHU0NCg2bNnq6ysTEVFRe3+baORI0cqPj7eqq/DN58btq/5u+++q0OHDrX7nJfsXO/2dLuSSkhI0KhRo1qcrhYVFWncuHFRStWSMUb33nuvXnvtNW3ZskWZmZnt3uf48eOqqKhQenp6FyQ8P8FgUB999JHS09NDLxt8fe3r6+u1bds2a9Z+1apVGjhwoG6++eY259m41uezvqNGjVJ8fHzYnMrKSh04cCDqX4OvCqq0tFSbN29W//79273PwYMH1dDQYNXX4ZvPDZvXXDr7ysGoUaOUnZ3d7lwb17tdUbxo44KtXbvWxMfHmxdffNF8+OGHpqCgwCQmJpojR45EO1rIz3/+c+N2u01xcbGprKwMbadOnTLGGFNTU2OWLFlidu7cacrKyszWrVvNtddeay677DITCASilnvJkiWmuLjYfPrpp+b99983U6ZMMUlJSaG1feyxx4zb7Tavvfaa2b9/v7nttttMenp6VDN/pampyQwePNjcf//9YeM2rXVNTY3Zu3ev2bt3r5FknnrqKbN3797QFXDns7533323GTRokNm8ebPZs2ePmThxosnOzjaNjY1Ry97Q0GCmTZtmBg0aZPbt2xf2nA8Gg8YYYw4fPmwefvhhs2vXLlNWVmY2btxorrzySjNixIhOzd5W7vN9bkRjzdt7rhhjjN/vN/369TPPP/98i/tHa70jrVuWlDHG/Mu//IvJyMgwCQkJZuTIkWGXdttAUqvbqlWrjDHGnDp1yuTm5poBAwaY+Ph4M3jwYJOfn2/Ky8ujmnvOnDkmPT3dxMfHG6/Xa2bOnGkOHjwY2t/c3GyWL19uPB6Pcblc5vrrrzf79++PYuK/eeutt4wkc+jQobBxm9Z669atrT4v8vPzjTHnt76nT5829957r0lJSTF9+/Y1U6ZM6ZLH0lb2srKycz7nt27daowxpry83Fx//fUmJSXFJCQkmCuuuML8/d//vTl+/HjUcp/vcyMaa97ec8UYY1544QXTt29fc/LkyRb3j9Z6Rxp/TwoAYK1u954UAKD3oKQAANaipAAA1qKkAADWoqQAANaipAAA1qKkAADWoqQAANaipAAA1qKkAADWoqQAANb6/wZKb8euaCFfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(i1==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <__main__.Tree object at 0x7f40dc873400>\n",
      "  <__main__.Tree object at 0x7f40dc81fdc0>\n",
      "  <__main__.Tree object at 0x7f40dc929db0>\n",
      "  <__main__.Tree object at 0x7f40dc92b490>\n",
      "  <__main__.Tree object at 0x7f40dc89b700>\n",
      "  <__main__.Tree object at 0x7f40dc89a050>\n",
      "  <__main__.Tree object at 0x7f40dc89be20>\n",
      "  <__main__.Tree object at 0x7f40dc8981f0>\n",
      "  <__main__.Tree object at 0x7f40dc89bbe0>\n",
      "  <__main__.Tree object at 0x7f40dc844ac0>\n",
      "  <__main__.Tree object at 0x7f40dc844160>\n",
      "  <__main__.Tree object at 0x7f40dc8477f0>\n",
      "  <__main__.Tree object at 0x7f40dc847760>\n",
      "  <__main__.Tree object at 0x7f40dc845960>\n",
      "  <__main__.Tree object at 0x7f40dc8d12d0>\n",
      "  <__main__.Tree object at 0x7f40dc8d1180>\n",
      "   <__main__.Tree object at 0x7f40dc8d1c90>\n",
      "  <__main__.Tree object at 0x7f40dc8d1540>\n",
      "  <__main__.Tree object at 0x7f40dc8d1480>\n",
      "  <__main__.Tree object at 0x7f40dc8d1420>\n"
     ]
    }
   ],
   "source": [
    "generate_mask_tree(ops).traverse_inorder(lambda x, y: print(\" \"*y, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f40dc92b4c0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(i1==10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# getting some layer of outputs\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mresetState()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[1;32m      6\u001b[0m     image, target \u001b[38;5;241m=\u001b[39m dRP500\u001b[38;5;241m.\u001b[39mtrain[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# getting some layer of outputs\n",
    "import pickle\n",
    "model.resetState()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    image, target = dRP500.train[0]\n",
    "    output1 = model(image.unsqueeze(dim=0).cuda())\n",
    "    output2 = model(image.unsqueeze(dim=0).cuda())\n",
    "    output3 = model(image.unsqueeze(dim=0).cuda())\n",
    "    \n",
    "plt.imshow(output1.cpu().squeeze() > 0.1)\n",
    "with open(\"dummy_op.pkl\", \"wb\") as f:\n",
    "    pickle.dump([o.cpu().squeeze().numpy() > 0.1 for o in [output1, output2, output3]], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"dummy_op.pkl\", \"rb\") as r:\n",
    "    ops = pickle.load(r)\n",
    "    ops = [o.astype(int) for o in ops]\n",
    "    \n",
    "i1 = ops[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f40dc8447f0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(i1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = ops[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth: 3, pred: 3\n",
      "mask group generated\n",
      "generated gt tree\n",
      "flood (0, 0)\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m h_train \u001b[38;5;241m=\u001b[39m \u001b[43mhierarchy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[81], line 258\u001b[0m, in \u001b[0;36mhierarchy_score\u001b[0;34m(model, dataset, threshold, device, norm)\u001b[0m\n\u001b[1;32m    255\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    256\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 258\u001b[0m his_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mhierarchical_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m precision \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m his_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhierarchical-precision\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    260\u001b[0m recall \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m his_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhierarchical-recall\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[81], line 204\u001b[0m, in \u001b[0;36mhierarchical_metrics\u001b[0;34m(truth, pred)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated gt tree\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# prediction list\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m pred_tree \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_mask_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated pred tree\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    207\u001b[0m preds \u001b[38;5;241m=\u001b[39m get_mask_list(pred)\n",
      "Cell \u001b[0;32mIn[81], line 176\u001b[0m, in \u001b[0;36mgenerate_mask_tree\u001b[0;34m(masks)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_mask_tree\u001b[39m(masks: List[np\u001b[38;5;241m.\u001b[39mndarray]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tree:\n\u001b[1;32m    175\u001b[0m     root \u001b[38;5;241m=\u001b[39m Tree(np\u001b[38;5;241m.\u001b[39mones(masks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m))\n\u001b[0;32m--> 176\u001b[0m     mask_groups \u001b[38;5;241m=\u001b[39m {i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m: binary_mask_to_children(mask) \u001b[38;5;28;01mfor\u001b[39;00m i, mask \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(masks)}\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask group generated\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# generate mask hierarchy tree\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[81], line 176\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_mask_tree\u001b[39m(masks: List[np\u001b[38;5;241m.\u001b[39mndarray]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tree:\n\u001b[1;32m    175\u001b[0m     root \u001b[38;5;241m=\u001b[39m Tree(np\u001b[38;5;241m.\u001b[39mones(masks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m))\n\u001b[0;32m--> 176\u001b[0m     mask_groups \u001b[38;5;241m=\u001b[39m {i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m: \u001b[43mbinary_mask_to_children\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i, mask \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(masks)}\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask group generated\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# generate mask hierarchy tree\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[81], line 73\u001b[0m, in \u001b[0;36mbinary_mask_to_children\u001b[0;34m(mask)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbinary_mask_to_children\u001b[39m(mask: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Converts a compund binary mask to list of individual masks\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m        mask (torch.tensor): binary mask of objects\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     mask, n_children \u001b[38;5;241m=\u001b[39m \u001b[43mflood_fill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     children \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_children):\n",
      "Cell \u001b[0;32mIn[81], line 60\u001b[0m, in \u001b[0;36mflood_fill\u001b[0;34m(mask)\u001b[0m\n\u001b[1;32m     58\u001b[0m mask_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m index:\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mflood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_counter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     index \u001b[38;5;241m=\u001b[39m find_seed(mask)\n\u001b[1;32m     62\u001b[0m     mask_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[81], line 52\u001b[0m, in \u001b[0;36mflood\u001b[0;34m(mask, seed_x, seed_y, value)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dx, dy \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mproduct([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid(x\u001b[38;5;241m+\u001b[39mdx, y\u001b[38;5;241m+\u001b[39mdy) \u001b[38;5;129;01mand\u001b[39;00m mask[x\u001b[38;5;241m+\u001b[39mdx, y\u001b[38;5;241m+\u001b[39mdy] \u001b[38;5;241m==\u001b[39m flood_area:\n\u001b[0;32m---> 52\u001b[0m         \u001b[43mfill_pixels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mdx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mdy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h_train = hierarchy_score(model, dataset.train, threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "his",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
